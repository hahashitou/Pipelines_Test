<h1 id="pubsub-and-network-integration">Pub/Sub and Network
Integration</h1>
<h2 id="process-diagram">Process Diagram</h2>
<figure>
<img
src="https://serverlessoh.azureedge.net/public/pubsub-and-vnet-integration-progress-diagram.jpg"
alt="Pub/Sub and VNet Integration Progress Diagram" />
<figcaption aria-hidden="true">Pub/Sub and VNet Integration Progress
Diagram</figcaption>
</figure>
<h2 id="overview">Overview</h2>
<p>The primary objective of this challenge is to expose participants to
the following concepts:</p>
<ul>
<li>Azure Functions Premium with virtual network integration</li>
<li>Pub/Sub via Azure Service Bus topics and subscription filters
(filtering events that need extra action)</li>
<li>Messaging claim check pattern</li>
</ul>
<h2 id="happy-path">Happy Path</h2>
<ul>
<li>Participant should create a new Service Bus topic to which to send
messages.</li>
<li>Service Bus should be configured with a Private Endpoint connected
to the existing vNet using the ‘pub-sub-messages’ subnet.</li>
<li>Modify the Azure Function used in the prior challenge to publish
messages to a new Service Bus topic <strong>only</strong> if there is a
<code>receiptUrl</code> in the data received from Event Hub.
<ul>
<li>Use the UserProperties of a Service Bus Message/BrokeredMessage
type. The new property will need to have a key such as “TotalCost” and a
value such as 134.59. The property can be used by a Service Bus SQL
filter for a subscription.</li>
<li>It is possible to use an output binding if using C#.</li>
<li>If using JavaScript or Java, use the Azure SDK. Bindings will not
work (the UserProperty is not available and will be serialized as part
of the message). For JavaScript, see <a
href="https://docs.microsoft.com/azure/service-bus-messaging/service-bus-nodejs-how-to-use-topics-subscriptions-new-package#send-messages-to-a-topic">here</a>
for an example. This is a known issue (see <a
href="https://github.com/Azure/azure-webjobs-sdk/issues/2137">here</a>
and <a
href="https://github.com/Azure/Azure-Functions/issues/1139">here</a>).</li>
<li>If not already there, upgrade the Azure Function to Elastic
premium</li>
<li>Configure the Azure Function to use the ‘sale-processing’ subnet to
connect to allow connection to the Service Bus</li>
</ul></li>
<li>Create two Service Bus subscriptions, one to handle all messages,
and one to handle only messages where the total cost is greater than
$100.
<ul>
<li><strong>Note:</strong> Adding a filter to a Subsription can be done
via the portal, only after the subscription is created, via the editing
blade of the subscription. It can also be created using an ARM template
(<a
href="https://github.com/Azure/azure-quickstart-templates/blob/master/201-servicebus-create-topic-subscription-rule/azuredeploy.json">here</a>
or <a
href="https://docs.microsoft.com/azure/service-bus-messaging/service-bus-resource-manager-namespace-topic-with-rule">here</a>),
<a
href="https://docs.microsoft.com/cli/azure/servicebus/topic/subscription/rule?view=azure-cli-latest">Azure
CLI</a>, code (Azure SDK), or <a
href="https://github.com/paolosalvatori/ServiceBusExplorer">Service Bus
Explorer</a>.</li>
</ul></li>
<li>Create two functions (within the Functions Premium plan) to act as
subscribers. There should be one function per subscription.</li>
<li>For the function which retrieves and base64 encodes the PDF:
<ul>
<li>use a Service Bus trigger to receive the message</li>
<li>use a blob output binding with <a
href="https://docs.microsoft.com/azure/azure-functions/functions-bindings-expressions-patterns#create-guids">blob
output binding for a random guid</a> to set the file name</li>
<li>the receiptUrl should be a reference to an Azure storage blob using
a SAS URL, and thus should be downloadable within the Azure
function.</li>
<li>configured to use the ‘receipt-processing’ subnet to allow
connection to the Service Bus.</li>
</ul></li>
<li>Use the provided VM to view the files in Azure blob storage and
validate the messages are being sent to the service bus. Remotely access
the VM (using Azure Bastion) and then log into the Azure Portal (using
the Azure credentials for the OpenHack). Navigate to the Storage
Explorer in the portal and then browse to view the files in blob
storage.</li>
</ul>
<h2 id="coachs-notes">Coach’s Notes</h2>
<ul>
<li>VM (Jumpbox) Notes
<ul>
<li>Use Azure Bastion hato connect to the Jumpbox</li>
<li><em>Username:</em> serverless</li>
<li><em>Password:</em> Serverless4All!</li>
<li>VM will automatically shut down at 19:00 UTC each day</li>
</ul></li>
<li>The following Azure resources should be provisioned in advance
within the participant’s Azure subscription:
<ul>
<li>2 storage accounts
<ul>
<li>one for the VM’s diagnostic data (storage account name should begin
with ‘sohvmdiag’)</li>
<li>one for the storage of receipts (storage account name should begin
with ‘sohsales’). There should be two containers within this storage
account: ‘receipts’ and ‘receipts-high-value’</li>
</ul></li>
<li>1 Virtual Machine (’soh-jumpbox)
<ul>
<li>OS is Windows 10</li>
<li>VM uses a DevTestLab schedule to automatically shut down daily at
19:00 (no notification)</li>
</ul></li>
<li>1 Azure Bastion Host</li>
<li>1 Virtual Network (‘soh-vnet’)
<ul>
<li>4 subnets
<ul>
<li>‘receipt-processing’ - this is for use by the compute resource
(ideally an Azure Functions Premium plan) used to process messages from
the Service Bus for this challenge</li>
<li>‘sale-processing’ - this is for use by the compute resource (ideally
an Azure Functions Premium plan) used to update the event processing
service from the previous challenge to push into the Service Bus
<ul>
<li>if the hackers configure both functions to use the same app service
plan, either one of the above subnets can be used as they both have the
same configuration</li>
</ul></li>
<li>‘pub-sub-messages’ - this should be used by the Service Bus to
configure the private end points with</li>
<li>‘jumpbox’ - this is for use exclusively by the VM</li>
<li>‘AzureBastionSubnet’ - this is for use by the Azure Bastion host to
connect to the jumpbox</li>
</ul></li>
<li>receipt-processing subnets are configured with a virtual network
service endpoint for access to Microsoft.Storage resources.</li>
<li>1 network security group to allow access to the jumbox via Azure
Bastion</li>
</ul></li>
</ul></li>
</ul>
<p>The diagram below depicts the Azure resources which are created for
each team’s Azure subscription.</p>
<figure>
<img
src="./images/pubsub-and-network-challenge-existing-azure-resources.png"
alt="Azure resources" />
<figcaption aria-hidden="true">Azure resources</figcaption>
</figure>
<h2
id="why-service-bus-functions-virtual-machines-and-storage-accounts">Why
Service Bus, Functions, Virtual Machines, and Storage Accounts</h2>
<h3 id="service-bus">Service Bus</h3>
<ul>
<li>Fully-managed enterprise message broker with message queues and
pub/sub capabilities</li>
<li>Decouple actions and services from each other for load balancing,
safe routing, transferring data and control across boundaries, and
coordinating transactional work with a high-degree of reliability</li>
</ul>
<h3 id="azure-functions">Azure Functions</h3>
<ul>
<li>Azure functions allow your teams to write less code, maintain less
infrastructure and save on costs</li>
<li>Azure functions are lightweight and stand-alone. Functions can
easily break up monolithic applications and reduce your lead/cycle time,
allowing your teams to get code to production much more quickly and
efficiently</li>
</ul>
<h3 id="azure-virtual-machines">Azure Virtual Machines</h3>
<ul>
<li>On-demand, scalable, cost-efficient computing</li>
<li>No hardware management, but full control over networking and access,
OS, disks, and processor configurations like number of cores and
processing power</li>
</ul>
<h3 id="azure-storage">Azure Storage</h3>
<ul>
<li>Storage is durable, scalable, and highly available. Redundancy
ensures that your data is safe in the event of transient hardware
failures, whilst being massively scalable to meet the needs of today’s
applications</li>
<li>Storage is secure, with built in encryption and fine-grained access
control to configure particular and precise access for users to expose
only the storage data they should be allowed to access.</li>
</ul>
