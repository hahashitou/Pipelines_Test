<h1 id="process-distributor-order-batch-files">Process distributor order
batch files</h1>
<h2 id="background">Background</h2>
<p>Best For You Organics Company (BFYOC) receives orders from
distributors via flat files, similar to that of many businesses. These
files come in batches of three, however each file can come in at
different times. BFYOC would like your team to create an implementation
that can process the files as a batch, storing the data contained as a
single JSON object in a database.</p>
<h2 id="challenge">Challenge</h2>
<p>The purchase order information from some of the distributors arrive
in batches. Each batch is made up of exactly three different files, each
with different information about orders, as described below:</p>
<ul>
<li><p>Type 1: order header details. For example:
<code>20180518151300-OrderHeaderDetails.csv</code></p></li>
<li><p>Type 2: order line items. For example:
<code>20180518151300-OrderLineItems.csv</code></p></li>
<li><p>Type 3: product information for the batch. For example:
<code>20180518151300-ProductInformation.csv</code></p></li>
</ul>
<p>For these example file names the batch that binds them together is
the file name prefix <code>20180518151300</code>. Be sure to review the
contents of the files, as a single order header details file may contain
multiple orders.</p>
<p>Before continuing to the challenge, create a Storage Account of kind
<code>StorageV2 (general purpose v2)</code> in your Azure Subscription,
and then create a new Blob container in it.</p>
<p>You will be required to post your team table number, the storage
account connection string, and the blob container name. The distributor
systems will start sending batches of flat files with order details into
your blob storage container every 1 minute. The date based prefix of the
file names will indicate what files belong to the same batch.</p>
<blockquote>
<p>HINT: Your team table number will be assigned if one exists. If not,
you will need to create a unique table name such as
<code>&lt;yourcity&gt;-table-&lt;sometablenumber&gt;</code>. You will
need this table number in future challenges, so you may wish to write it
down or keep it somewhere you can easily retrieve for future
registrations. Review the swagger documentation or discuss with your
coach for more information.</p>
</blockquote>
<p>Make an HTTP POST call to the
<code>/team/registerStorageAccount</code> endpoint of the <a
href="https://petstore.swagger.io/?url=https://serverlessohmanagementapi.trafficmanager.net/api/definition">Serverless
OpenHack API System</a> to register your team’s storage account.</p>
<p><strong>Take note of the teamTableNumber used in this registration.
It will be required in later challenges.</strong></p>
<p><strong>Make sure to note that the API is case-sensitive, so all
parameters and parameter values must match case. Review the swagger
documentation to make sure you have the BODY composed correctly <a
href="https://petstore.swagger.io/?url=https://serverlessohmanagementapi.trafficmanager.net/api/definition#/Register%20Storage%20Account/register">here</a></strong></p>
<p>Your challenge is to work as a team to create a solution that:</p>
<ul>
<li><p>Waits until all the files for the same batch arrive before
processing them.</p></li>
<li><p>Once all three files for a batch have been received, make an HTTP
POST call to the <code>/order/combineOrderContent</code> endpoint of the
<a
href="https://petstore.swagger.io/?url=https://serverlessohmanagementapi.trafficmanager.net/api/definition">Serverless
OpenHack API System</a>, which will combine the content and return a
single JSON document per order.</p></li>
<li><p>Insert the JSON document of each order into your database as a
separate entry/record.</p></li>
</ul>
<p><strong>Note: The Serverless Open Hack will periodically check team
registrations and delete those with invalid storage accounts and
services used in later challenges. To ensure your team’s registration
isn’t deleted, be sure not to delete the Azure services used here and
subsequent challenges.</strong></p>
<blockquote>
<p>HINT: Make sure to register EventGrid as a resource provider on your
Azure Subscription before trying to respond to storage events. Failure
to register Event Grid will result in an inability to create
subscriptions that respond to Azure storage events</p>
</blockquote>
<h2 id="success-criteria">Success Criteria</h2>
<ul>
<li>Demonstrate to your coach how you implemented the workflow to read,
combine, and insert the data from the batches of flat files into one
JSON document per order into a database. All the details from the flat
files need to be in the JSON documents generated.</li>
</ul>
<h2 id="references">References</h2>
<ul>
<li><p><a
href="https://docs.microsoft.com/en-us/azure/event-grid/custom-event-quickstart-portal">Register
Event Grid</a></p></li>
<li><p><a href="https://docs.microsoft.com/azure/event-grid/overview">An
introduction to Azure Event Grid</a></p></li>
<li><p><a
href="https://docs.microsoft.com/azure/storage/blobs/storage-blob-event-overview">Event
Grid: Reacting to Blob Storage events</a></p></li>
<li><p><a
href="https://docs.microsoft.com/azure/azure-functions/durable-functions-overview">Durable
Functions overview</a></p></li>
<li><p><a
href="https://docs.microsoft.com/azure/logic-apps/logic-apps-batch-process-send-receive-messages">Send,
receive, and batch process messages in Logic Apps</a></p></li>
</ul>
<h2 id="progress-diagram">Progress Diagram</h2>
<figure>
<img
src="https://serverlessoh.azureedge.net/public/order-batch-files-progress-diagram.jpg"
alt="Process distributor order batch files progress diagram" />
<figcaption aria-hidden="true">Process distributor order batch files
progress diagram</figcaption>
</figure>
