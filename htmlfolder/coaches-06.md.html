<h1 id="process-distributor-order-batch-files">Process distributor order
batch files</h1>
<h2 id="progress-diagram">Progress Diagram</h2>
<figure>
<img
src="https://serverlessoh.azureedge.net/public/order-batch-files-progress-diagram.jpg"
alt="Process distributor order batch files progress diagram" />
<figcaption aria-hidden="true">Process distributor order batch files
progress diagram</figcaption>
</figure>
<h2 id="happy-path">Happy Path</h2>
<p>One of the following options:</p>
<ul>
<li>Event Grid trigger to one Azure Function that queries if two files
appear at the same time it might cause a problem reading the files at
the same time from storage; create an extra file for each batch inside
the function and put a lease on the file inside the function code and
also add a retry whenever there is already a lease on the file to avoid
this</li>
<li>Event Grid to Azure Function that loads file contents to a SQL DB /
CosmosDB and a separate function that checks from time to time if any
have content for all three then merges them into a separate Cosmos
collection</li>
<li>Event Grid to Durable Functions that creates sub orchestrators for
each batch when the first file arrives then RaiseEventAsync for the
others; sub orchestrator runs an activity function with the details of
all three files and the activity function parses and inserts the data
(one per order) into Cosmos<br />
</li>
<li>Use Logic Apps with the batch trigger (one LA with event grid that
sends info about the files to a second LA that has the batch trigger
configured to release after 3 messages) and an Azure Function that is
called by the batch triggered LA that handles the loading of the files,
parsing, and inserting into Cosmos</li>
</ul>
<h2 id="coaches-notes">Coaches Notes</h2>
<ul>
<li><p>This one might need more hands on by you to help them with their
approach.</p></li>
<li><p>When posting to register the storage account, the team should use
a unique table number. The API for post can be found <a
href="https://serverlessohmanagementapi.trafficmanager.net/api/definition">here</a>.
What matters is that the team table number is unique, such as
seattle-table-1 or london-table-8. If team table numbers are not
assigned, encourage the teams to use a unique table name and to write it
down as they will need it in future steps. Please be aware this will
send a great deal of traffic to their storage account for 48-72 hours.
Please inform them not to break the connection while the OH is active,
as they need to keep the registration active for future challenges, and
if they break the connection, they will get de-registered.</p></li>
</ul>
<blockquote>
<p>NOTE: Student accounts will also be de-registered if more than 72
hours (3 days) have passed since registration. If the student hits this
threshold, have them re-register their storage account to restart the
processing.</p>
</blockquote>
<ul>
<li><p>The <em>serverlessohmanagementapi</em> application is case
sensitive, so all parameters in the body must match exactly for each
call, as well as there can be no case variation for filenames and links
to the files in azure storage. Review the swagger documentation for
exact body composition requirements for each method.</p></li>
<li><p>Durable Functions in Node.js is supported only for version 2.x of
the Azure Functions runtime. Requires version 1.7.0 or later of the
Durable Functions extension.</p></li>
<li><p>Python and Java currently don’t support durable functions. These
teams will need to use alternate methods to accomplish this
challenge.</p></li>
<li><p>If the team’s storage account container is private, the urls
supplied to the /order/combineOrderContent endpoint must contain a SAS
token.</p></li>
<li><p>Cosmos DB Output binding doesn’t allow for exception handling.
Depending on the triggering approach the team uses this will manifest in
different ways when errors occur during the saving to the database. Have
the team discuss this and different ways of dealing with this.</p></li>
<li><p>When the CosmosDB table is registered, a partition key is used,
such as “id”, “FileName”, or “filename”. Assuming the partition key was
“FileName”, the logic app connector must connect and follow these setup
instructions:</p>
<ul>
<li><p>DatabaseID: selected from connection<br />
</p></li>
<li><p>CollectionID: selected from connection<br />
</p></li>
<li><p>Document: Use left and right curly braces, then each field in
quotes with each associated value, separated by commas. <strong>Do not
forget to include your partition key and its value in this
document.</strong></p></li>
<li><p>Add a new parameter, and select “Partition Key Value”. In the
resulting text box, add the partition key’s value in quotes (to match
the document above). For example, the left hand would be non-editable
text stating ‘Partition key value’ and there would be a text box on the
right to enter information. In that textbox, add the partition key’s
<strong>value</strong> in quotes, such as:
<strong>“myorderfile.xls”</strong>. Since the key is likely changing per
run, encourage the use of a variable to store the partition key’s
value.</p></li>
</ul></li>
<li><p>When writing to CosmosDB in Logic Apps the Partition Key
parameter needs to be added as a new parameter to the CosmosDB Create or
Update document connector. The value needs to be surrounded by quotes.
The partition also needs to be sent as part of the body of the document
to create. If you don’t see your partition key’s value in both the
document and the Partition Key Value parameter, the create or update
document will not work. Additionally, you can review the designer JSON
and validate that the “x-ms-documentdb-raw-partitionkey” is set with a
value.</p></li>
<li><p>If you get an error for Microsoft.EventGrid resource provider was
not registered for the attendee subscription, make sure to follow the
steps to register the EventGrid resource provider from <a
href="https://docs.microsoft.com/en-us/azure/event-grid/custom-event-quickstart-portal">Enable
Event Grid Resource Provider</a></p></li>
</ul>
<h2
id="why-azure-functions-azure-logic-apps-azure-event-grid-and-azure-storage">Why
Azure Functions, Azure Logic Apps, Azure Event Grid, and Azure
Storage</h2>
<h3 id="azure-functions">Azure Functions</h3>
<ul>
<li>Azure functions allow your teams to write less code, maintain less
infrastructure and save on costs.</li>
<li>Azure functions are lightweight and stand-alone. Functions can
easily break up monolithic applications and reduce your lead/cycle time,
allowing your teams to get code to production much more quickly and
efficiently.</li>
</ul>
<h3 id="azure-logic-apps">Azure Logic Apps</h3>
<ul>
<li>Logic apps are able to connect to just about anything, with over 200
connectors, and can be triggered at will, on a schedule, or as a
response to an event</li>
<li>Logic apps are easy to use, with workflows that can be created with
just a few configurations using a powerful drag-and-drop editor
approach, logic apps can allow your team to quickly and easily
orchestrate complex logic</li>
</ul>
<h3 id="azure-event-grid">Azure Event Grid</h3>
<ul>
<li>Easily build application with event-based architectures</li>
<li>Route specific events to different endpoints, multicast to multiple
endpoints, and make sure your events are reliably delivered</li>
</ul>
<h3 id="azure-storage">Azure Storage</h3>
<ul>
<li>Storage is durable, scalable, and highly available. Redundancy
ensures that your data is safe in the event of transient hardware
failures, whilst being massively scalable to meet the needs of today’s
applications</li>
<li>Storage is secure, with built in encryption and fine-grained access
control to configure particular and precise access for users to expose
only the storage data they should be allowed to access.</li>
</ul>
